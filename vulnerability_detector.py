"""
AI-Powered Vulnerability Detector
Uses Groq AI and ML Model to intelligently detect and analyze vulnerabilities
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import parse_qs, urljoin, urlparse
import re
import joblib
import numpy as np
import pandas as pd
import os


class VulnerabilityDetector:
    """
    Scans web pages and uses AI to detect vulnerabilities
    """

    def __init__(
        self,
        enable_ai=True,
        max_pages=10,
        smart_crawl=True,
        model_path='vulnerability_model.pkl',
        enable_intel_model=True,
        intel_model_path='bug_intel_model.pkl',
        max_ai_validations=20,
    ):
        self.enable_ai = enable_ai
        self.max_pages = max_pages
        self.smart_crawl = smart_crawl
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Security Scanner)"
        }
        self.owasp_top10_2021 = {
            "A01:2021": "Broken Access Control",
            "A02:2021": "Cryptographic Failures",
            "A03:2021": "Injection",
            "A04:2021": "Insecure Design",
            "A05:2021": "Security Misconfiguration",
            "A06:2021": "Vulnerable and Outdated Components",
            "A07:2021": "Identification and Authentication Failures",
            "A08:2021": "Software and Data Integrity Failures",
            "A09:2021": "Security Logging and Monitoring Failures",
            "A10:2021": "Server-Side Request Forgery (SSRF)",
        }
        
        # Load ML model
        self.ml_model = None
        self.enable_ml = False
        
        try:
            if model_path and os.path.exists(model_path):
                self.ml_model = joblib.load(model_path)
                self.enable_ml = True
                print(f"[+] ML Model loaded successfully from {model_path}")
                print(f"[+] Model predicts: {', '.join(self.ml_model.classes_)}")
            else:
                print(f"[-] ML Model not found at {model_path}")
        except Exception as e:
            print(f"[-] Failed to load ML model: {e}")
            self.enable_ml = False

        # Load threat-intel self-trained model
        self.enable_intel_model = False
        self.intel_model = None
        self.intel_pipeline = None
        if enable_intel_model and intel_model_path and os.path.exists(intel_model_path):
            try:
                self.intel_model = joblib.load(intel_model_path)
                self.intel_pipeline = self.intel_model.get("pipeline") if isinstance(self.intel_model, dict) else None
                if self.intel_pipeline is not None:
                    self.enable_intel_model = True
                    print(f"[+] Threat-intel model loaded from {intel_model_path}")
            except Exception as e:
                print(f"[-] Failed to load threat-intel model: {e}")
        self.max_ai_validations = max_ai_validations

    def scan_target(self, target_url, groq_orchestrator):
        """
        Scan a target URL and detect vulnerabilities
        """
        print(f"\n[*] Scanning: {target_url}")

        vulnerabilities = []

        # Crawl the site
        pages = self._crawl_site(target_url)

        print(f"[*] Crawled {len(pages)} pages")

        # Analyze each page
        for page in pages:
            # ML Model prediction (NEW!)
            if self.enable_ml and self.ml_model:
                ml_vulns = self._ml_detect_vulnerabilities(page)
                vulnerabilities.extend(ml_vulns)

            if self.enable_intel_model and self.intel_pipeline:
                intel_vulns = self._intel_detect_vulnerabilities(page)
                vulnerabilities.extend(intel_vulns)
            
            # Traditional pattern-based detection
            traditional_vulns = self._detect_traditional_vulnerabilities(page)
            vulnerabilities.extend(traditional_vulns)

            # AI-powered detection
            if self.enable_ai and groq_orchestrator:
                ai_vulns = self._ai_detect_vulnerabilities(page, groq_orchestrator)
                vulnerabilities.extend(ai_vulns)

        # Add URL-based vulnerabilities
        vulnerabilities.extend(self._check_url_vulnerabilities(target_url))

        # Add header-based vulnerabilities
        vulnerabilities.extend(self._check_security_headers(target_url))

        print(f"[+] Found {len(vulnerabilities)} potential vulnerabilities")

        # AI validation of vulnerabilities
        if self.enable_ai and groq_orchestrator and vulnerabilities:
            validated_vulns = []
            validation_budget = self.max_ai_validations
            for idx, vuln in enumerate(vulnerabilities):
                if idx >= validation_budget:
                    # Keep remaining findings without AI validation to avoid hitting API limits.
                    validated_vulns.append(vuln)
                    continue
                validation = groq_orchestrator.validate_vulnerability(vuln)

                if validation.get('is_valid', True):
                    # Update vulnerability with validation results
                    vuln['severity'] = validation.get('refined_severity', vuln['severity'])
                    vuln['exploitation_difficulty'] = validation.get('exploitation_difficulty', 'Medium')
                    vuln['business_impact'] = validation.get('business_impact', 'Unknown')
                    vuln['risk_score'] = validation.get('risk_score', vuln.get('risk_score'))
                    vuln['ai_validated'] = True
                    validated_vulns.append(vuln)

            normalized = self._normalize_and_enrich_vulnerabilities(validated_vulns)
            return self._run_verification_pipeline(normalized)

        normalized = self._normalize_and_enrich_vulnerabilities(vulnerabilities)
        return self._run_verification_pipeline(normalized)

    def _crawl_site(self, start_url):
        """Crawl website pages"""
        visited = set()
        to_visit = [start_url]
        pages_data = []

        base_domain = urlparse(start_url).netloc

        while to_visit and len(visited) < self.max_pages:
            url = to_visit.pop(0)

            if url in visited:
                continue

            visited.add(url)

            try:
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=10,
                    allow_redirects=True
                )

                if 'text/html' not in response.headers.get('Content-Type', ''):
                    continue

                soup = BeautifulSoup(response.text, 'html.parser')

                # Extract page data
                page_data = {
                    'url': url,
                    'html': response.text,
                    'status_code': response.status_code,
                    'headers': dict(response.headers),
                    'forms': self._extract_forms(soup),
                    'scripts': self._extract_scripts(soup),
                    'links': self._extract_links(soup, url),
                    'inputs': self._extract_inputs(soup),
                    'cookies': response.cookies.get_dict()
                }

                pages_data.append(page_data)

                # Smart crawling: prioritize interesting pages
                if self.smart_crawl:
                    interesting_links = [
                        link for link in page_data['links']
                        if self._is_interesting_page(link)
                    ]
                    to_visit.extend(interesting_links[:5])
                else:
                    # Add all internal links
                    for link in page_data['links']:
                        if urlparse(link).netloc == base_domain:
                            to_visit.append(link)

            except Exception as e:
                print(f"[-] Error crawling {url}: {e}")
                continue

        return pages_data

    def _is_interesting_page(self, url):
        """Determine if a page is interesting for security testing"""
        interesting_patterns = [
            'login', 'signin', 'auth', 'admin', 'dashboard',
            'upload', 'form', 'search', 'api', 'user', 'account',
            'payment', 'checkout', 'profile', 'settings'
        ]

        url_lower = url.lower()
        return any(pattern in url_lower for pattern in interesting_patterns)

    def _extract_forms(self, soup):
        """Extract all forms from page"""
        forms = []
        for form in soup.find_all('form'):
            forms.append({
                'action': form.get('action', ''),
                'method': form.get('method', 'GET').upper(),
                'inputs': [
                    {
                        'name': inp.get('name', ''),
                        'type': inp.get('type', 'text'),
                        'value': inp.get('value', '')
                    }
                    for inp in form.find_all('input')
                ]
            })
        return forms

    def _extract_scripts(self, soup):
        """Extract all scripts from page"""
        scripts = []
        for script in soup.find_all('script'):
            src = script.get('src', '')
            scripts.append({
                'src': src,
                'external': bool(src and ('http://' in src or 'https://' in src)),
                'inline': script.string if not src else None
            })
        return scripts

    def _extract_links(self, soup, base_url):
        """Extract all links from page"""
        links = []
        for link in soup.find_all('a', href=True):
            href = urljoin(base_url, link['href'])
            links.append(href)
        return links

    def _extract_inputs(self, soup):
        """Extract all inputs from page"""
        inputs = []
        for inp in soup.find_all('input'):
            inputs.append({
                'type': inp.get('type', 'text'),
                'name': inp.get('name', ''),
                'id': inp.get('id', '')
            })
        return inputs

    def _ml_detect_vulnerabilities(self, page):
        """
        Use ML model to predict vulnerabilities based on page features
        Model features: ['forms', 'scripts', 'missing_csp']
        Model classes: ['Misconfiguration', 'SQL Injection', 'XSS']
        """
        vulnerabilities = []
        url = page['url']
        
        try:
            # Extract features for the model (returns DataFrame)
            features_df = self._extract_ml_features(page)
            
            # Make prediction
            prediction = self.ml_model.predict(features_df)[0]
            probability = self.ml_model.predict_proba(features_df)[0]
            
            # Get confidence for the predicted class
            predicted_class_idx = list(self.ml_model.classes_).index(prediction)
            confidence = int(probability[predicted_class_idx] * 100)
            
            # Only report if confidence is above threshold
            if confidence >= 60:  # 60% confidence threshold
                
                # Map ML predictions to vulnerability details
                vuln_details = {
                    'SQL Injection': {
                        'type': 'ML-Detected SQL Injection Risk',
                        'severity': 'High',
                        'description': 'Machine learning model detected patterns indicating SQL injection vulnerability',
                        'recommendation': 'Use parameterized queries, implement input validation, and apply principle of least privilege to database accounts',
                        'cwe_id': 'CWE-89'
                    },
                    'XSS': {
                        'type': 'ML-Detected XSS Risk',
                        'severity': 'High',
                        'description': 'Machine learning model detected patterns indicating cross-site scripting vulnerability',
                        'recommendation': 'Implement output encoding, use Content Security Policy headers, and validate/sanitize all user inputs',
                        'cwe_id': 'CWE-79'
                    },
                    'Misconfiguration': {
                        'type': 'ML-Detected Security Misconfiguration',
                        'severity': 'Medium',
                        'description': 'Machine learning model detected security misconfigurations in the application',
                        'recommendation': 'Review security headers, implement CSP, ensure proper error handling, and follow security best practices',
                        'cwe_id': 'CWE-16'
                    }
                }
                
                vuln_info = vuln_details.get(prediction, {
                    'type': f'ML-Detected {prediction}',
                    'severity': 'Medium',
                    'description': f'Machine learning model detected potential {prediction}',
                    'recommendation': 'Manual security review recommended',
                    'cwe_id': 'CWE-693'
                })
                
                vulnerabilities.append({
                    'url': url,
                    'type': vuln_info['type'],
                    'severity': vuln_info['severity'],
                    'confidence': confidence,
                    'description': vuln_info['description'],
                    'location': 'ML Model Analysis',
                    'recommendation': vuln_info['recommendation'],
                    'cwe_id': vuln_info['cwe_id'],
                    'detection_method': 'Machine Learning',
                    'ml_prediction': prediction,
                    'ml_confidence_scores': {
                        cls: f"{prob*100:.1f}%" 
                        for cls, prob in zip(self.ml_model.classes_, probability)
                    }
                })
                
                print(f"[ML] Detected {prediction} with {confidence}% confidence on {url}")
        
        except Exception as e:
            print(f"[-] ML detection error on {url}: {e}")
        
        return vulnerabilities

    def _intel_detect_vulnerabilities(self, page):
        """
        Use self-trained threat-intel model to detect modern bug patterns.
        Conservative by default: only emits findings >= 80% confidence.
        """
        vulnerabilities = []
        url = page['url']
        try:
            text = BeautifulSoup(page.get('html', ''), 'html.parser').get_text(" ", strip=True)
            text = text[:6000]
            if not text:
                return vulnerabilities

            pred = self.intel_pipeline.predict([text])[0]
            confidence = 0
            if hasattr(self.intel_pipeline, "predict_proba"):
                proba = self.intel_pipeline.predict_proba([text])[0]
                confidence = int(max(proba) * 100)

            if confidence < 80:
                return vulnerabilities

            severity_map = {
                "RCE": "Critical",
                "SQL Injection": "High",
                "Auth Bypass": "High",
                "SSRF": "High",
                "XSS": "High",
                "Path Traversal": "Medium",
                "CSRF": "Medium",
                "Info Disclosure": "Medium",
                "Misconfiguration": "Medium",
            }
            cwe_map = {
                "RCE": "CWE-94",
                "SQL Injection": "CWE-89",
                "Auth Bypass": "CWE-287",
                "SSRF": "CWE-918",
                "XSS": "CWE-79",
                "Path Traversal": "CWE-22",
                "CSRF": "CWE-352",
                "Info Disclosure": "CWE-200",
                "Misconfiguration": "CWE-16",
            }

            label = str(pred)
            vulnerabilities.append({
                'url': url,
                'type': f'Intel-Model {label} Indicator',
                'severity': severity_map.get(label, 'Medium'),
                'confidence': confidence,
                'description': (
                    'Self-trained threat-intel model flagged this page as similar to recent '
                    f'public vulnerabilities ({label}).'
                ),
                'location': 'Threat-Intel Model Analysis',
                'recommendation': (
                    'Prioritize manual validation and targeted testing for this bug class before deployment.'
                ),
                'cwe_id': cwe_map.get(label, 'CWE-693'),
                'detection_method': 'Threat Intel Self-Training Model',
                'intel_prediction': label,
            })
        except Exception as e:
            print(f"[-] Threat-intel detection error on {url}: {e}")
        return vulnerabilities
    
    def _extract_ml_features(self, page):
        """
        Extract features required by the ML model
        Features: ['forms', 'scripts', 'missing_csp']
        """
        import pandas as pd
        
        # Feature 1: Number of forms
        num_forms = len(page['forms'])
        
        # Feature 2: Number of scripts
        num_scripts = len(page['scripts'])
        
        # Feature 3: Missing CSP (1 if missing, 0 if present)
        headers = page.get('headers', {})
        has_csp = 'Content-Security-Policy' in headers or 'content-security-policy' in headers
        missing_csp = 0 if has_csp else 1
        
        # Return as pandas DataFrame with proper feature names
        return pd.DataFrame([[num_forms, num_scripts, missing_csp]], 
                          columns=['forms', 'scripts', 'missing_csp'])

    def _detect_traditional_vulnerabilities(self, page):
        """Traditional pattern-based vulnerability detection"""
        vulnerabilities = []
        url = page['url']

        # Check for SQL Injection patterns
        if self._check_sql_injection_patterns(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential SQL Injection',
                'severity': 'High',
                'confidence': 60,
                'description': 'Form inputs without proper sanitization detected',
                'location': 'Form inputs',
                'recommendation': 'Use parameterized queries and input validation',
                'cwe_id': 'CWE-89'
            })

        # Check for XSS vulnerabilities
        if self._check_xss_patterns(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential Cross-Site Scripting (XSS)',
                'severity': 'High',
                'confidence': 55,
                'description': 'Unescaped user input or dangerous JavaScript patterns detected',
                'location': 'Page content / Scripts',
                'recommendation': 'Implement output encoding and Content Security Policy',
                'cwe_id': 'CWE-79'
            })

        # Check for CSRF
        if self._check_csrf_vulnerability(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Missing CSRF Protection',
                'severity': 'Medium',
                'confidence': 70,
                'description': 'Forms without CSRF tokens detected',
                'location': 'Form elements',
                'recommendation': 'Implement CSRF tokens for all state-changing operations',
                'cwe_id': 'CWE-352'
            })

        # Check for sensitive data exposure
        if self._check_sensitive_data_exposure(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Sensitive Data Exposure',
                'severity': 'Medium',
                'confidence': 65,
                'description': 'Potentially sensitive information found in page source',
                'location': 'HTML comments / Script variables',
                'recommendation': 'Remove sensitive data from client-side code',
                'cwe_id': 'CWE-200'
            })

        # Check for access control weaknesses
        if self._check_access_control_exposure(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential Broken Access Control Exposure',
                'severity': 'High',
                'confidence': 58,
                'description': 'Administrative or privileged paths appear directly discoverable without access gating indicators',
                'location': 'Public links / Route exposure',
                'recommendation': 'Enforce server-side authorization checks on all privileged resources and hide admin routes from unauthenticated users',
                'cwe_id': 'CWE-284'
            })

        # Check for authentication/session weaknesses
        if self._check_authentication_weakness(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential Authentication/Session Weakness',
                'severity': 'Medium',
                'confidence': 62,
                'description': 'Login/session handling patterns appear weak (missing secure token/cookie/session hardening indicators)',
                'location': 'Forms / Cookie metadata',
                'recommendation': 'Use strong session management, secure cookie flags, and robust authentication controls (MFA, lockout, token rotation)',
                'cwe_id': 'CWE-287'
            })

        # Check for integrity protection weaknesses
        if self._check_software_integrity_risk(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential Software/Data Integrity Risk',
                'severity': 'Medium',
                'confidence': 60,
                'description': 'External scripts detected without integrity or trusted-source hardening indicators',
                'location': 'Script includes',
                'recommendation': 'Use Subresource Integrity (SRI), signed artifacts, and strict dependency governance for third-party resources',
                'cwe_id': 'CWE-353'
            })

        # Check for SSRF-like indicators
        if self._check_ssrf_indicators(page):
            vulnerabilities.append({
                'url': url,
                'type': 'Potential SSRF Indicator',
                'severity': 'Medium',
                'confidence': 56,
                'description': 'URL-fetch style input patterns detected that may allow server-side request forgery if backend validation is weak',
                'location': 'Input parameters / API route hints',
                'recommendation': 'Apply URL allowlists, DNS/IP egress filtering, and strict parser validation for all outbound fetch functionality',
                'cwe_id': 'CWE-918'
            })

        return vulnerabilities

    def _check_sql_injection_patterns(self, page):
        """Check for SQL injection vulnerability patterns"""
        # Check forms for SQL-injectable inputs
        for form in page['forms']:
            if form['method'] == 'GET':
                return True  # GET forms are more susceptible

            # Check for database-related inputs
            for inp in form['inputs']:
                if inp['type'] in ['text', 'search'] and not inp['name'].startswith('csrf'):
                    return True

        return False

    def _check_xss_patterns(self, page):
        """Check for XSS vulnerability patterns"""
        html = page['html']

        # Check for unescaped output patterns
        xss_patterns = [
            r'<script[^>]*>[^<]*</script>',
            r'eval\(',
            r'innerHTML\s*=',
            r'document\.write\(',
            r'on\w+\s*=\s*["\']'
        ]

        for pattern in xss_patterns:
            if re.search(pattern, html, re.IGNORECASE):
                return True

        return False

    def _check_csrf_vulnerability(self, page):
        """Check for CSRF vulnerability"""
        for form in page['forms']:
            if form['method'] == 'POST':
                # Check if form has CSRF token
                has_csrf_token = any(
                    'csrf' in inp['name'].lower() or 'token' in inp['name'].lower()
                    for inp in form['inputs']
                )

                if not has_csrf_token:
                    return True

        return False

    def _check_sensitive_data_exposure(self, page):
        """Check for sensitive data in page source"""
        html = page['html'].lower()

        sensitive_patterns = [
            'password', 'api_key', 'secret', 'token',
            'private_key', 'aws_', 'database', 'connection'
        ]

        # Check HTML comments
        comments = re.findall(r'<!--(.*?)-->', html, re.DOTALL)
        for comment in comments:
            if any(pattern in comment for pattern in sensitive_patterns):
                return True

        return False

    def _check_access_control_exposure(self, page):
        """Heuristic check for potentially exposed privileged routes."""
        privileged_keywords = ("admin", "internal", "manage", "superuser", "root")
        auth_markers = ("logout", "sign out", "account", "profile", "session")
        links = [str(link).lower() for link in page.get('links', [])]
        html = str(page.get('html', '')).lower()

        has_privileged_link = any(any(k in link for k in privileged_keywords) for link in links)
        has_auth_marker = any(marker in html for marker in auth_markers)
        return has_privileged_link and not has_auth_marker

    def _check_authentication_weakness(self, page):
        """Heuristic check for authentication and session handling weaknesses."""
        url = str(page.get('url', '')).lower()
        forms = page.get('forms', [])
        cookies = page.get('cookies', {}) or {}

        has_login_form = False
        for form in forms:
            input_names = [str(inp.get('name', '')).lower() for inp in form.get('inputs', [])]
            input_types = [str(inp.get('type', '')).lower() for inp in form.get('inputs', [])]
            if "password" in input_types or any("password" in name for name in input_names):
                has_login_form = True
                break

        # Cookie flags are not available from cookie key/value map; treat known session cookie names as risk signals.
        session_cookie_names = ("session", "phpsessid", "jsessionid", "sid", "auth")
        weak_session_signal = any(any(token in name.lower() for token in session_cookie_names) for name in cookies.keys())

        return has_login_form and (url.startswith("http://") or weak_session_signal)

    def _check_software_integrity_risk(self, page):
        """Detect external script usage that appears to miss integrity controls."""
        scripts = page.get('scripts', [])
        html = str(page.get('html', '')).lower()
        external_count = sum(1 for s in scripts if s.get('external'))
        has_sri = 'integrity=' in html
        return external_count >= 2 and not has_sri

    def _check_ssrf_indicators(self, page):
        """Heuristic indicator for URL-fetch style parameters commonly abused for SSRF."""
        input_names = [
            str(inp.get('name', '')).lower()
            for form in page.get('forms', [])
            for inp in form.get('inputs', [])
        ]
        suspicious_names = {"url", "uri", "callback", "return_url", "next", "redirect", "endpoint", "fetch"}
        route_hints = ("proxy", "fetch", "webhook", "import", "crawl")
        url = str(page.get('url', '')).lower()
        return bool(set(input_names).intersection(suspicious_names)) or any(hint in url for hint in route_hints)

    def _ai_detect_vulnerabilities(self, page, groq_orchestrator):
        """Use AI to detect vulnerabilities"""
        try:
            vulnerabilities = groq_orchestrator.analyze_page_content(
                url=page['url'],
                html_content=page['html'],
                forms_data=page['forms'],
                scripts_data=page['scripts']
            )

            # Add URL to each vulnerability
            for vuln in vulnerabilities:
                vuln['url'] = page['url']

            return vulnerabilities

        except Exception as e:
            print(f"[-] AI detection failed: {e}")
            return []

    def _check_url_vulnerabilities(self, url):
        """Check for URL-based vulnerabilities"""
        vulnerabilities = []
        parsed = urlparse(url)

        # Check for HTTP (not HTTPS)
        if url.startswith('http://'):
            vulnerabilities.append({
                'url': url,
                'type': 'Insecure Protocol (HTTP)',
                'severity': 'Medium',
                'confidence': 100,
                'description': 'Website uses HTTP instead of HTTPS',
                'location': 'Protocol',
                'recommendation': 'Implement HTTPS with valid SSL/TLS certificate',
                'cwe_id': 'CWE-319'
            })

        # Detect sensitive parameter names in URL query strings
        sensitive_params = {
            "token", "access_token", "auth", "apikey", "api_key", "key",
            "password", "passwd", "secret", "session", "jwt"
        }
        query_keys = {k.lower() for k in parse_qs(parsed.query).keys()}
        found_sensitive = sorted(query_keys.intersection(sensitive_params))
        if found_sensitive:
            vulnerabilities.append({
                'url': url,
                'type': 'Sensitive Data in URL Parameters',
                'severity': 'High',
                'confidence': 85,
                'description': (
                    f"Sensitive query parameters exposed in URL: {', '.join(found_sensitive)}"
                ),
                'location': 'URL Query String',
                'recommendation': 'Move sensitive values to secure headers or POST body and rotate exposed secrets',
                'cwe_id': 'CWE-598'
            })

        return vulnerabilities

    def _check_security_headers(self, url):
        """Check for missing security headers"""
        vulnerabilities = []

        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            headers = response.headers

            # Check for important security headers
            security_headers = {
                'X-Frame-Options': 'Medium',
                'X-Content-Type-Options': 'Low',
                'Strict-Transport-Security': 'Medium',
                'Content-Security-Policy': 'Medium',
                'X-XSS-Protection': 'Low'
            }

            for header, severity in security_headers.items():
                if header not in headers:
                    vulnerabilities.append({
                        'url': url,
                        'type': f'Missing Security Header: {header}',
                        'severity': severity,
                        'confidence': 95,
                        'description': f'{header} header not set',
                        'location': 'HTTP Response Headers',
                        'recommendation': f'Add {header} header to HTTP responses',
                        'cwe_id': 'CWE-16'
                    })

        except:
            pass

        return vulnerabilities

    def _normalize_and_enrich_vulnerabilities(self, vulnerabilities):
        """
        Normalize, de-duplicate, and rank findings to reduce noisy output.
        """
        severity_map = {
            "critical": "Critical",
            "high": "High",
            "medium": "Medium",
            "low": "Low",
            "info": "Info",
            "informational": "Info",
        }
        severity_weight = {"Critical": 95, "High": 75, "Medium": 55, "Low": 35, "Info": 15}

        dedup = {}
        for vuln in vulnerabilities:
            if not isinstance(vuln, dict):
                continue

            severity = str(vuln.get("severity", "Medium")).strip().lower()
            normalized_severity = severity_map.get(severity, "Medium")
            confidence = vuln.get("confidence", 50)
            try:
                confidence = int(confidence)
            except (TypeError, ValueError):
                confidence = 50
            confidence = max(0, min(100, confidence))

            if vuln.get("risk_score") is None:
                base = severity_weight.get(normalized_severity, 50)
                vuln["risk_score"] = min(100, int(base + (confidence * 0.1)))

            vuln["severity"] = normalized_severity
            vuln["confidence"] = confidence
            vuln.setdefault("location", "Unknown")
            vuln.setdefault("recommendation", "Manual security review recommended")
            vuln.setdefault("description", "Potential security issue detected")
            owasp_id, owasp_name = self._map_to_owasp(vuln)
            vuln["owasp_top10"] = owasp_id
            vuln["owasp_category"] = owasp_name

            key = (
                vuln.get("url", ""),
                vuln.get("type", ""),
                vuln.get("location", ""),
                vuln.get("description", ""),
            )

            existing = dedup.get(key)
            if not existing or vuln["confidence"] > existing.get("confidence", 0):
                dedup[key] = vuln

        ranked = sorted(
            dedup.values(),
            key=lambda v: (int(v.get("risk_score", 0)), int(v.get("confidence", 0))),
            reverse=True,
        )
        return ranked

    def _map_to_owasp(self, vuln):
        """Map a finding to OWASP Top 10 2021 category."""
        cwe = str(vuln.get("cwe_id", "")).upper()
        text = (
            f"{vuln.get('type', '')} "
            f"{vuln.get('description', '')} "
            f"{vuln.get('location', '')}"
        ).lower()

        # CWE-driven mapping first.
        if any(code in cwe for code in ("CWE-284", "CWE-285", "CWE-639")):
            return "A01:2021", self.owasp_top10_2021["A01:2021"]
        if any(code in cwe for code in ("CWE-319", "CWE-200", "CWE-598", "CWE-311")):
            return "A02:2021", self.owasp_top10_2021["A02:2021"]
        if any(code in cwe for code in ("CWE-89", "CWE-79", "CWE-74", "CWE-77")):
            return "A03:2021", self.owasp_top10_2021["A03:2021"]
        if "design" in text:
            return "A04:2021", self.owasp_top10_2021["A04:2021"]
        if any(code in cwe for code in ("CWE-16", "CWE-933")):
            return "A05:2021", self.owasp_top10_2021["A05:2021"]
        if "outdated" in text or "deprecated" in text:
            return "A06:2021", self.owasp_top10_2021["A06:2021"]
        if any(code in cwe for code in ("CWE-287", "CWE-307", "CWE-613")):
            return "A07:2021", self.owasp_top10_2021["A07:2021"]
        if any(code in cwe for code in ("CWE-353", "CWE-494", "CWE-829")):
            return "A08:2021", self.owasp_top10_2021["A08:2021"]
        if any(code in cwe for code in ("CWE-778", "CWE-223")):
            return "A09:2021", self.owasp_top10_2021["A09:2021"]
        if "CWE-918" in cwe:
            return "A10:2021", self.owasp_top10_2021["A10:2021"]

        # Keyword fallback.
        if "access control" in text or "authorization" in text or "admin" in text:
            return "A01:2021", self.owasp_top10_2021["A01:2021"]
        if "sensitive data" in text or "https" in text or "crypto" in text or "ssl" in text:
            return "A02:2021", self.owasp_top10_2021["A02:2021"]
        if "sql" in text or "xss" in text or "inject" in text or "csrf" in text:
            return "A03:2021", self.owasp_top10_2021["A03:2021"]
        if "misconfiguration" in text or "header" in text:
            return "A05:2021", self.owasp_top10_2021["A05:2021"]
        if "authentication" in text or "session" in text or "login" in text:
            return "A07:2021", self.owasp_top10_2021["A07:2021"]
        if "integrity" in text or "sri" in text:
            return "A08:2021", self.owasp_top10_2021["A08:2021"]
        if "logging" in text or "monitor" in text:
            return "A09:2021", self.owasp_top10_2021["A09:2021"]
        if "ssrf" in text or "server-side request forgery" in text:
            return "A10:2021", self.owasp_top10_2021["A10:2021"]

        # Default to insecure design when uncertain in taxonomy.
        return "A04:2021", self.owasp_top10_2021["A04:2021"]

    def _run_verification_pipeline(self, vulnerabilities):
        """
        Verification stage to reduce false positives.
        Produces: verification_status, evidence, and confidence band.
        """
        verified = []
        for vuln in vulnerabilities:
            verified_vuln = self._verify_single_finding(vuln)
            verified.append(verified_vuln)

        verified.sort(
            key=lambda v: (int(v.get("risk_score", 0)), int(v.get("confidence", 0))),
            reverse=True,
        )
        return verified

    def _verify_single_finding(self, vuln):
        severity_rank = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1, "Info": 0}
        ordered_severity = ["Info", "Low", "Medium", "High", "Critical"]

        findings_text = (
            f"{vuln.get('type', '')} "
            f"{vuln.get('description', '')} "
            f"{vuln.get('location', '')}"
        ).lower()
        source = str(vuln.get("detection_method", "")).lower()
        confidence = int(vuln.get("confidence", 50))

        evidence = []
        signal_count = 0
        deterministic = False

        # Signal 1: deterministic checks can be treated as confirmed.
        if "missing security header" in findings_text:
            deterministic = True
            signal_count += 1
            evidence.append("Header missing verified via HTTP response inspection.")
        elif "insecure protocol (http)" in findings_text:
            deterministic = True
            signal_count += 1
            evidence.append("URL scheme is HTTP (not HTTPS).")
        elif "sensitive data in url parameters" in findings_text:
            deterministic = True
            signal_count += 1
            evidence.append("Sensitive query key names detected in URL parameters.")

        # Signal 2: strong model confidence.
        if "machine learning" in source and confidence >= 80:
            signal_count += 1
            evidence.append("ML detector confidence >= 80%.")
        if "threat intel self-training model" in source and confidence >= 85:
            signal_count += 1
            evidence.append("Threat-intel model confidence >= 85%.")

        # Signal 3: AI triage validation.
        if vuln.get("ai_validated", False):
            signal_count += 1
            evidence.append("AI validation accepted this finding.")

        # Signal 4: heuristic category support.
        if "sql" in findings_text:
            signal_count += 1
            evidence.append("SQLi category indicators matched detector heuristics.")
        elif "cross-site scripting" in findings_text or "xss" in findings_text:
            signal_count += 1
            evidence.append("XSS category indicators matched detector heuristics.")
        elif "csrf" in findings_text:
            signal_count += 1
            evidence.append("CSRF token protection weakness observed.")
        elif "sensitive data exposure" in findings_text:
            signal_count += 1
            evidence.append("Sensitive data keyword patterns observed in page source.")
        elif "access control" in findings_text or "admin" in findings_text:
            signal_count += 1
            evidence.append("Potential privileged resource exposure indicators observed.")
        elif "authentication" in findings_text or "session" in findings_text:
            signal_count += 1
            evidence.append("Authentication/session weakness indicators observed.")
        elif "integrity" in findings_text or "sri" in findings_text:
            signal_count += 1
            evidence.append("Software/data integrity control gaps observed.")
        elif "ssrf" in findings_text:
            signal_count += 1
            evidence.append("SSRF-like URL fetch indicator patterns observed.")

        if deterministic or signal_count >= 3:
            verification_status = "confirmed"
        elif signal_count == 2:
            verification_status = "probable"
        elif signal_count == 1:
            verification_status = "suspected"
        else:
            verification_status = "info"

        # Policy: weakly supported findings cannot stay high/critical.
        severity = vuln.get("severity", "Medium")
        if severity not in severity_rank:
            severity = "Medium"
        if verification_status in {"suspected", "info"} and severity_rank[severity] >= severity_rank["High"]:
            severity = "Medium"
        elif verification_status == "info" and severity == "Medium":
            severity = "Low"
        vuln["severity"] = severity

        # Risk cap by verification quality.
        risk_caps = {"confirmed": 100, "probable": 85, "suspected": 60, "info": 35}
        try:
            risk_score = int(vuln.get("risk_score", 50))
        except (TypeError, ValueError):
            risk_score = 50
        vuln["risk_score"] = min(risk_score, risk_caps[verification_status])

        # Band used by reports/UI.
        band_map = {
            "confirmed": "Confirmed",
            "probable": "Probable",
            "suspected": "Suspected",
            "info": "Informational",
        }
        vuln["verification_status"] = verification_status
        vuln["verification_signal_count"] = signal_count
        vuln["verification_evidence"] = evidence
        vuln["confidence_band"] = band_map[verification_status]

        # Keep top-level proof text for compatibility with existing UI.
        if evidence and not vuln.get("proof"):
            vuln["proof"] = " | ".join(evidence[:2])

        # Make sure severity string is canonical if touched by policy.
        if severity in ordered_severity:
            vuln["severity"] = ordered_severity[ordered_severity.index(severity)]

        return vuln

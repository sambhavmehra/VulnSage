"""
Agentic penetration testing runner.

Combines low-level penetration tests with AI agent prioritization/remediation.
Use only for authorized testing scopes.
"""

from __future__ import annotations

from dataclasses import asdict
from typing import Any, Dict, Mapping, Optional

from attack_path_agent import AttackPathAgent
from penetration_tester import PenetrationTester
from groq_orchestrator import GroqOrchestrator
from remediation_engine import RemediationEngine
from security_agent import SecurityAgent
from self_training_agent import SelfTrainingAgent
from threat_intel_agent import ThreatIntelAgent


class AgenticPentestRunner:
    """Orchestrates pentest execution and optional AI-agent analysis."""

    def __init__(self, tester: Optional[PenetrationTester] = None) -> None:
        self.tester = tester or PenetrationTester()

    def run(
        self,
        url: str,
        params: Mapping[str, Any],
        method: str = "GET",
        headers: Optional[Mapping[str, str]] = None,
        enable_time_based: bool = True,
        time_retries: int = 2,
        min_delay_delta: float = 3.0,
        enable_agentic_ai: bool = True,
        enable_attack_paths: bool = True,
        enable_remediation_fixes: bool = True,
        threat_intel_mode: str = "cached",
        intel_days: int = 30,
        intel_max_items: int = 120,
        enable_self_training: bool = False,
    ) -> Dict[str, Any]:
        """
        Run SQLi + XSS + baseline comparison tests, then optional agentic AI analysis.
        """
        sqli_results = self.tester.send_sqli_payloads(
            url=url,
            params=params,
            method=method,
            headers=headers,
        )

        time_results = []
        if enable_time_based:
            time_results = self.tester.detect_time_based_blind_sqli(
                url=url,
                params=params,
                method=method,
                headers=headers,
                retries=time_retries,
                min_delay_delta=min_delay_delta,
            )

        findings = self._normalize_findings(url=url, sqli_results=sqli_results, time_results=time_results)

        threat_intel = self._load_threat_intel(
            mode=threat_intel_mode,
            max_items=intel_max_items,
            days=intel_days,
        )
        findings = self._enrich_findings_with_intel(findings, threat_intel)

        orchestrator = None
        agentic_error = None
        if (enable_agentic_ai or enable_attack_paths or enable_remediation_fixes) and findings:
            try:
                orchestrator = GroqOrchestrator()
            except Exception as exc:
                agentic_error = str(exc)

        domain = url.split("/")[2] if "://" in url and len(url.split("/")) > 2 else url
        domain_info = {"domain": domain, "url": url}
        if threat_intel:
            domain_info["threat_intel_summary"] = {
                "collected_at": threat_intel.get("collected_at"),
                "total_items": threat_intel.get("total_items", 0),
                "sources": threat_intel.get("sources", {}),
            }

        agentic_analysis = None
        if enable_agentic_ai and findings and orchestrator:
            try:
                agent = SecurityAgent(orchestrator)
                agentic_analysis = agent.analyze_scan_results(findings, domain_info)
            except Exception as exc:
                agentic_error = str(exc)

        attack_paths = None
        if enable_attack_paths and findings:
            try:
                attack_agent = AttackPathAgent(orchestrator=orchestrator)
                attack_paths = attack_agent.analyze(findings, domain_info=domain_info)
            except Exception as exc:
                attack_paths = {"error": str(exc)}

        remediation_fixes = {}
        if enable_remediation_fixes and findings and orchestrator:
            try:
                remediation_engine = RemediationEngine(orchestrator)
                for finding in findings:
                    if str(finding.get("severity", "")).lower() in {"high", "critical"}:
                        vuln_type = finding.get("type", "Unknown")
                        remediation_fixes[vuln_type] = remediation_engine.generate_fix(finding)
            except Exception as exc:
                remediation_fixes = {"error": str(exc)}

        self_training_result = None
        if enable_self_training and threat_intel and threat_intel.get("items"):
            try:
                trainer = SelfTrainingAgent()
                self_training_result = trainer.train_from_intel(threat_intel)
            except Exception as exc:
                self_training_result = {"success": False, "message": str(exc)}

        return {
            "url": url,
            "parameters_tested": list(params.keys()),
            "sqli_results": [asdict(item) for item in sqli_results],
            "time_based_results": [asdict(item) for item in time_results],
            "findings": findings,
            "summary": {
                "total_sqli_tests": len(sqli_results),
                "likely_sqli_count": sum(1 for item in sqli_results if item.likely_sqli),
                "reflected_xss_count": sum(1 for item in sqli_results if item.reflected_xss),
                "time_based_tests": len(time_results),
                "time_based_vulnerable_count": sum(1 for item in time_results if item.likely_vulnerable),
                "total_findings": len(findings),
            },
            "agentic_analysis": agentic_analysis,
            "attack_paths": attack_paths,
            "remediation_fixes": remediation_fixes,
            "threat_intel": threat_intel,
            "self_training_result": self_training_result,
            "agentic_error": agentic_error,
        }

    @staticmethod
    def _load_threat_intel(mode: str, max_items: int, days: int) -> Optional[Dict[str, Any]]:
        normalized_mode = (mode or "off").strip().lower()
        if normalized_mode not in {"off", "cached", "live"}:
            normalized_mode = "cached"
        if normalized_mode == "off":
            return None
        agent = ThreatIntelAgent()
        if normalized_mode == "live":
            return agent.collect_latest_bugs(max_items=max_items, days=days)
        return agent.load_cached_bugs()

    @staticmethod
    def _enrich_findings_with_intel(findings: list[dict], intel: Optional[Dict[str, Any]]) -> list[dict]:
        if not intel or not intel.get("items"):
            return findings

        intel_items = intel.get("items", [])
        for finding in findings:
            ftype = str(finding.get("type", "")).lower()
            if "sql" in ftype:
                keywords = ("sql injection", "sqli", "cwe-89")
            elif "xss" in ftype or "cross-site" in ftype:
                keywords = ("cross-site scripting", "xss", "cwe-79")
            elif "csrf" in ftype:
                keywords = ("csrf", "cross-site request forgery", "cwe-352")
            else:
                keywords = tuple()

            if not keywords:
                continue

            hits = []
            exploited_hits = 0
            for item in intel_items:
                blob = (
                    f"{item.get('title', '')} {item.get('description', '')} {item.get('cwe_id', '')}"
                ).lower()
                if any(k in blob for k in keywords):
                    hits.append(
                        {
                            "id": item.get("id"),
                            "source": item.get("source"),
                            "known_exploited": bool(item.get("known_exploited")),
                            "published": item.get("published"),
                            "url": item.get("url"),
                        }
                    )
                    if item.get("known_exploited"):
                        exploited_hits += 1
                if len(hits) >= 5:
                    break

            if hits:
                finding["threat_intel_matches"] = hits
                if exploited_hits > 0:
                    finding["risk_score"] = min(100, int(finding.get("risk_score", 50)) + 8)
                    finding["confidence"] = min(100, int(finding.get("confidence", 50)) + 5)
                    finding["intel_known_exploited_hits"] = exploited_hits
        return findings

    @staticmethod
    def _normalize_findings(url: str, sqli_results: list, time_results: list) -> list[dict]:
        findings = []

        for item in sqli_results:
            if item.likely_sqli:
                findings.append(
                    {
                        "type": "Potential SQL Injection",
                        "severity": "High",
                        "confidence": 90 if item.comparison.sql_error_detected else 75,
                        "risk_score": 85 if item.comparison.sql_error_detected else 70,
                        "url": url,
                        "description": f"Parameter '{item.parameter}' responded abnormally for payload '{item.payload}'",
                        "evidence": {
                            "status_code_changed": item.comparison.status_code_changed,
                            "similarity_ratio": item.comparison.similarity_ratio,
                            "sql_error_detected": item.comparison.sql_error_detected,
                            "response_time": item.response_time,
                        },
                        "cwe_id": "CWE-89",
                    }
                )
            if item.reflected_xss:
                findings.append(
                    {
                        "type": "Potential Reflected XSS",
                        "severity": "High",
                        "confidence": 80,
                        "risk_score": 72,
                        "url": url,
                        "description": f"Payload reflection detected on parameter '{item.parameter}'",
                        "evidence": {"payload": item.payload},
                        "cwe_id": "CWE-79",
                    }
                )

        for item in time_results:
            if item.likely_vulnerable:
                findings.append(
                    {
                        "type": "Potential Time-based Blind SQL Injection",
                        "severity": "High",
                        "confidence": 88,
                        "risk_score": 84,
                        "url": url,
                        "description": (
                            f"Injected delay observed on parameter '{item.parameter}' "
                            f"(delta={item.delay_delta:.2f}s)"
                        ),
                        "evidence": {
                            "payload": item.payload,
                            "baseline_avg": item.average_baseline_time,
                            "injected_avg": item.average_injected_time,
                            "delay_delta": item.delay_delta,
                        },
                        "cwe_id": "CWE-89",
                    }
                )

        return findings
